---
title: OpenAI 12 Days 总结
categories: [ai, openai]
date: 2024-12-22
author: iugo
last_modified_at: 2024-12-24 10:35+08:00
---

<details lang="zh" open>
<summary>中文版本</summary>
<div markdown="1">

## 发布会

OpenAI 最新办了一场 12 天 "发布会": <https://openai.com/12-days/>

国内文章: <https://www.infoq.cn/article/WXPMviOWQ1LNZhqZC5ZE>

总结这几天的内容, 核心为:

1. ChatGPT Pro 服务, 200 美元/月 (Day 1)
2. 正式发布 o1 模型 (Day 1, 9)
3. 正式发布 Sora 模型 (Day 3)
4. 技术预览 (微调与 o3 模型) (Day 2, 12)
5. 更多应用层面的更新 (创作者助手, 苹果集成, 会话整理, 多媒体信息, 搜索,
   电话版 ChatGPT 等) (Day 4, 5, 6, 7, 8, 10, 11)

应用层面的创建无疑是收入的一个重要增长点. 但是对于 OpenAI 来说, 应用不是撒手锏,
模型才是.

所以这里面除了影响营收的 Pro 版本的收费, Sam 仅参加了模型相关发布 o1, Sora, o3.

## 模型

感觉有意义的点还不如 Ilya Sutskever 在 NeurIPS 2024 的演讲.

不过都在一个发力: **逻辑性**

AI 的幻觉问题比较严重, 这个问题其实也是 AI 缺乏逻辑性的一个表现.

可是人类的神经元就可以让自己有逻辑, 那 AI 为什么不能?

这就是 AI 的下一步方向, 不是找更多数据, 而是利用当前数据如何让 "逻辑性" 显现.

这种逻辑性, 而非知识性的问题我们也遇到了. 针对一些稍微复杂一点的逻辑问题,
当前主流模型都回答得不好 (应该说不对).

</div>
</details>

<details lang="en">
<summary>English Version</summary>
<div markdown="1">

## Launch Event

OpenAI recently held a 12-day "launch event": <https://openai.com/12-days/>

Key announcements during these days include:

1. ChatGPT Pro service at $200/month (Day 1)
2. Official release of o1 model (Day 1, 9)
3. Official release of Sora model (Day 3)
4. Technical previews (fine-tuning and o3 model) (Day 2, 12)
5. More application-level updates (Creator Assistant, Apple integration,
   conversation organization, multimedia handling, search, phone version of
   ChatGPT, etc.) (Day 4, 5, 6, 7, 8, 10, 11)

Application-level innovations are undoubtedly an important growth point for
revenue. However, for OpenAI, applications are not their trump card - models are.

That's why among all these announcements, Sam only participated in model-related
releases: o1, Sora, and o3.

## Models

The meaningful points here are not as significant as Ilya Sutskever's speech at
NeurIPS 2024.

However, they all focus on one direction: **logical reasoning**

AI's hallucination problem is quite serious, which is actually a manifestation
of AI's lack of logical reasoning ability.

Human neurons can enable logical thinking, so why can't AI?

This is the next direction for AI - not finding more data, but utilizing existing
data to manifest "logical reasoning".

We've also encountered this issue of logical reasoning versus knowledge. Current
mainstream models don't perform well (or more accurately, don't perform correctly)
on slightly more complex logical problems.

</div>
</details>
